{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"),sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"),sep='\\t')\n",
    "\n",
    "tags = np.array(train_features['tag'],dtype = np.str)\n",
    "list1 = []\n",
    "for i in range(tags.size):\n",
    "    list1.extend(tags[i].split(','))\n",
    "list2 = list(set(list1))\n",
    "list2.sort()\n",
    "tags1 = np.zeros((5240,200))\n",
    "for i in range(5240):\n",
    "    for j in range(200):\n",
    "        tempList = tags[i].split(',')\n",
    "        if list2[j] in tempList:\n",
    "            tags1[i,j]=1\n",
    "            \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "columnsToEncode = list(train_features.select_dtypes(include=['category','object']))\n",
    "le = LabelEncoder()\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "        train_features[feature] = le.fit_transform(train_features[feature].astype(str))\n",
    "    except:\n",
    "        print('Error encoding ' + feature)\n",
    "        \n",
    "columnsToEncode = list(train_labels.select_dtypes(include=['category','object']))\n",
    "le = LabelEncoder()\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "        train_labels[feature] = le.fit_transform(train_labels[feature].astype(str))\n",
    "    except:\n",
    "        print('Error encoding ' + feature)\n",
    "        \n",
    "temp_features = np.array(train_features)\n",
    "temp_features = np.delete(temp_features,4,axis = 1)\n",
    "for i in range(5240):\n",
    "    temp_features[i,3] = temp_features[i,3]+1915\n",
    "#print(temp_features[:,3])\n",
    "new_features = np.append(tags1,temp_features[:,4:],axis = 1)\n",
    "\n",
    "train_labels1 = np.array(train_labels)\n",
    "\n",
    "distric = np.zeros((18,1)).flatten()\n",
    "for i in range(train_labels1.shape[0]):\n",
    "    \n",
    "    distric[train_labels1[i,1]] = distric[train_labels1[i,1]]+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"),sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"),sep='\\t')\n",
    "\n",
    "valid_tags = np.array(valid_features['tag'],dtype = np.str)\n",
    "\n",
    "valid_tags1 = np.zeros((299,200))\n",
    "for i in range(299):\n",
    "    for j in range(200):\n",
    "        tempList = valid_tags[i].split(',')\n",
    "        if list2[j] in tempList:\n",
    "            valid_tags1[i,j]=1\n",
    "            \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "columnsToEncode = list(valid_features.select_dtypes(include=['category','object']))\n",
    "le = LabelEncoder()\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "        valid_features[feature] = le.fit_transform(valid_features[feature].astype(str))\n",
    "    except:\n",
    "        print('Error encoding ' + feature)\n",
    "        \n",
    "\n",
    "\n",
    "columnsToEncode = list(valid_labels.select_dtypes(include=['category','object']))\n",
    "le = LabelEncoder()\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "        valid_labels[feature] = le.fit_transform(valid_labels[feature].astype(str))\n",
    "    except:\n",
    "        print('Error encoding ' + feature)\n",
    "        \n",
    "temp_valid_features = np.array(valid_features)\n",
    "temp_valid_features = np.delete(temp_valid_features,4,axis = 1)\n",
    "for i in range(299):\n",
    "    temp_valid_features[i,3] = temp_valid_features[i,3]+1915\n",
    "\n",
    "new_valid_features = np.append(valid_tags1,temp_valid_features[:,4:],axis = 1)\n",
    "\n",
    "valid_labels1 = np.array(valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Accuracy:\n",
      "38.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Speed/anaconda2/envs/python3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "subset_train = np.append(new_features[:,:200],new_features[:,307:],axis = 1)\n",
    "#print(subset_train.shape)\n",
    "\n",
    "subset_valid = np.append(new_valid_features[:,:200],new_valid_features[:,307:],axis=1)\n",
    "#print(subset_valid.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrModel = LogisticRegression(C=1.0, penalty='l2', tol=0.01)\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "\n",
    "X_train = ss.fit_transform(subset_train)\n",
    "Y_train = train_labels1[:,1]\n",
    "\n",
    "X_valid = ss.transform(subset_valid)\n",
    "Y_valid = valid_labels1[:,1]\n",
    "\n",
    "lrModel.fit(X_train,Y_train)\n",
    "score = lrModel.score(X_valid,Y_valid)\n",
    "result = np.array(lrModel.predict(X_valid))\n",
    "#print(\"Logistic regression，Sum： %d Error : %d\" % (new_valid_features.shape[0],(valid_labels1[:,1] != result).sum()))\n",
    "print(\"Logistic regression Accuracy:\\n\"+'%.2f%%'%(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression precision(macro):\n",
      "34.30%\n",
      "Logistic regression recall(macro):\n",
      "28.28%\n",
      "Logistic regression F-Score(macro):\n",
      "31.00%\n"
     ]
    }
   ],
   "source": [
    "P_R = np.zeros((18,4))\n",
    "actual = valid_labels1[:,-1]\n",
    "predicted = result.flatten()\n",
    "num_of_each_grade = np.zeros((18,1)).flatten()\n",
    "for i in range(18):\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    sum3 = 0\n",
    "    sum4 = 0\n",
    "    sum_of_instance = 0\n",
    "    for j in range(len(actual)):\n",
    "        if actual[j]==predicted[j]==(i):\n",
    "            sum1 = sum1+1\n",
    "        if actual[j]==(i)!=predicted[j]:\n",
    "            sum2 = sum2+1\n",
    "        if predicted[j]==(i)!=actual[j]:\n",
    "            sum3 = sum3+1\n",
    "        if predicted[j]!=(i) and actual[j]!=(i):\n",
    "            sum4 = sum4+1\n",
    "        if actual[j]==(i):\n",
    "            sum_of_instance = sum_of_instance+1\n",
    "    num_of_each_grade[i] = sum_of_instance\n",
    "    P_R[i,0] = sum1\n",
    "    P_R[i,1] = sum2\n",
    "    P_R[i,2] = sum3\n",
    "    P_R[i,3] = sum4\n",
    "\n",
    "closer_evaluation = np.zeros((18,3))\n",
    "for i in range(18):\n",
    "    if((P_R[i,0]+P_R[i,2])!=0):\n",
    "        closer_evaluation[i,0]=P_R[i,0]/(P_R[i,0]+P_R[i,2])\n",
    "    if((P_R[i,0]+P_R[i,1])!=0):\n",
    "        closer_evaluation[i,1]=P_R[i,0]/(P_R[i,0]+P_R[i,1])\n",
    "    P = closer_evaluation[i,0]\n",
    "    R = closer_evaluation[i,1]\n",
    "    if(P==0 and R==0):\n",
    "        closer_evaluation[i,2]=0\n",
    "    else:\n",
    "        closer_evaluation[i,2]= 2*P*R/(P+R)\n",
    "precision = 0\n",
    "for i in range(18):\n",
    "    precision = precision + closer_evaluation[i,0]\n",
    "precision = precision/18\n",
    "\n",
    "recall = 0\n",
    "for i in range(18):\n",
    "    recall = recall + closer_evaluation[i,1]\n",
    "recall = recall/18\n",
    "\n",
    "fscore = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"Logistic regression precision(macro):\\n\"+'%.2f%%'%(precision*100))\n",
    "print(\"Logistic regression recall(macro):\\n\"+'%.2f%%'%(recall*100))\n",
    "print(\"Logistic regression F-Score(macro):\\n\"+'%.2f%%'%(fscore*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:\n",
      "11.04%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(new_features, train_labels1[:,1])\n",
    "y_pred=clf.predict(new_valid_features)\n",
    "\n",
    "sum1 = new_valid_features.shape[0]\n",
    "errors = (valid_labels1[:,1] != y_pred).sum()\n",
    "#print(\"Naive Bayes，Sum： %d Error : %d\" % (sum1,errors))\n",
    "print(\"Naive Bayes Accuracy:\\n\"+'%.2f%%'%((1-errors/sum1)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes precision(macro):\n",
      "27.79%\n",
      "Naive Bayes recall(macro):\n",
      "19.09%\n",
      "Naive Bayes F-Score(macro):\n",
      "22.63%\n"
     ]
    }
   ],
   "source": [
    "P_R = np.zeros((18,4))\n",
    "actual = valid_labels1[:,-1]\n",
    "predicted = y_pred.flatten()\n",
    "num_of_each_grade = np.zeros((18,1)).flatten()\n",
    "for i in range(18):\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    sum3 = 0\n",
    "    sum4 = 0\n",
    "    sum_of_instance = 0\n",
    "    for j in range(len(actual)):\n",
    "        if actual[j]==predicted[j]==(i):\n",
    "            sum1 = sum1+1\n",
    "        if actual[j]==(i)!=predicted[j]:\n",
    "            sum2 = sum2+1\n",
    "        if predicted[j]==(i)!=actual[j]:\n",
    "            sum3 = sum3+1\n",
    "        if predicted[j]!=(i) and actual[j]!=(i):\n",
    "            sum4 = sum4+1\n",
    "        if actual[j]==(i):\n",
    "            sum_of_instance = sum_of_instance+1\n",
    "    num_of_each_grade[i] = sum_of_instance\n",
    "    P_R[i,0] = sum1\n",
    "    P_R[i,1] = sum2\n",
    "    P_R[i,2] = sum3\n",
    "    P_R[i,3] = sum4\n",
    "\n",
    "closer_evaluation = np.zeros((18,3))\n",
    "for i in range(18):\n",
    "    if((P_R[i,0]+P_R[i,2])!=0):\n",
    "        closer_evaluation[i,0]=P_R[i,0]/(P_R[i,0]+P_R[i,2])\n",
    "    if((P_R[i,0]+P_R[i,1])!=0):\n",
    "        closer_evaluation[i,1]=P_R[i,0]/(P_R[i,0]+P_R[i,1])\n",
    "    P = closer_evaluation[i,0]\n",
    "    R = closer_evaluation[i,1]\n",
    "    if(P==0 and R==0):\n",
    "        closer_evaluation[i,2]=0\n",
    "    else:\n",
    "        closer_evaluation[i,2]= 2*P*R/(P+R)\n",
    "precision = 0\n",
    "for i in range(18):\n",
    "    precision = precision + closer_evaluation[i,0]\n",
    "precision = precision/18\n",
    "\n",
    "recall = 0\n",
    "for i in range(18):\n",
    "    recall = recall + closer_evaluation[i,1]\n",
    "recall = recall/18\n",
    "\n",
    "fscore = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"Naive Bayes precision(macro):\\n\"+'%.2f%%'%(precision*100))\n",
    "print(\"Naive Bayes recall(macro):\\n\"+'%.2f%%'%(recall*100))\n",
    "print(\"Naive Bayes F-Score(macro):\\n\"+'%.2f%%'%(fscore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
